{"cells":[{"cell_type":"markdown","metadata":{"id":"_XaIh9kpwKe-"},"source":["#**Outlier Identification and Removal**"]},{"cell_type":"markdown","metadata":{"id":"X6QcSd0aTFwl"},"source":["In this tutorial, you will learn:\n","\n","* That an outlier is an unlikely observation in a dataset and may have one of many causes.\n","* How to use simple univariate statistics like standard deviation and interquartile range to\n","identify and remove outliers from a data sample.\n","* How to use an outlier detection model to identify and remove rows from a training dataset\n","in order to lift predictive modeling performance.\n","\n","Adapted from Jason Brownlee. 2020. [Data Preparation for Machine Learning](https://machinelearningmastery.com/data-preparation-for-machine-learning/)."]},{"cell_type":"markdown","metadata":{"id":"8GhsEsk5Qbrh"},"source":["#Outlier Identification and Removal\n","##What are Outliers?\n","\n","An outlier is an observation that is unlike the other observations. They are rare, distinct, or do\n","notâ€€fit in some way.\n","\n","We will generally define outliers as samples that are exceptionally far from the\n","mainstream of the data.\n","\n","Outliers can have many causes, such as:\n","\n","* Measurement or input error.\n","\n","* Data corruption.\n","\n","* True outlier observation.\n","\n","There is no precise way to define and identify outliers in general because of the specifics of\n","each dataset. Instead, you, or a domain expert, must interpret the raw observations and decide\n","whether a value is an outlier or not."]},{"cell_type":"markdown","metadata":{"id":"UfT4GpLuQ_qd"},"source":["##Remove outliers using Standard Deviation method"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6,"status":"ok","timestamp":1654551182652,"user":{"displayName":"Chuming Chen","userId":"17839229876463490728"},"user_tz":240},"id":"HKh3tdwURBl9","outputId":"353c064b-090d-4f4e-b466-4b857658ab84"},"outputs":[{"output_type":"stream","name":"stdout","text":["mean=50.049 stdv=4.994\n"]}],"source":["# identifiy outliers using Standard Deviation method\n","from numpy.random import seed\n","from numpy.random import randn\n","from numpy import mean\n","from numpy import std\n","# seed the random number generator\n","seed(1)\n","# generate univariate observations\n","data = 5 * randn(10000) + 50\n","# summarize\n","print('mean=%.3f stdv=%.3f' % (mean(data), std(data)))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yirudZwiRagS"},"outputs":[],"source":["# calculate summary statistics\n","data_mean, data_std = mean(data), std(data)\n","# define outliers\n","cut_off = data_std * 3\n","lower, upper = data_mean - cut_off, data_mean + cut_off"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":259,"status":"ok","timestamp":1654551214064,"user":{"displayName":"Chuming Chen","userId":"17839229876463490728"},"user_tz":240},"id":"e6m6_COPRevk","outputId":"0c981b8b-41ce-4c53-f1c0-e66651a57f82"},"outputs":[{"output_type":"stream","name":"stdout","text":["Identified outliers: 29\n"]}],"source":["# identify outliers\n","outliers = [x for x in data if x < lower or x > upper]\n","print('Identified outliers: %d' % len(outliers))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":309,"status":"ok","timestamp":1654551231729,"user":{"displayName":"Chuming Chen","userId":"17839229876463490728"},"user_tz":240},"id":"emxpuI6XRxtl","outputId":"e5c2da40-8fde-4a63-b934-d7027834debe"},"outputs":[{"output_type":"stream","name":"stdout","text":["Non-outlier observations: 9971\n"]}],"source":["# remove outliers\n","outliers_removed = [x for x in data if x >= lower and x <= upper]\n","print('Non-outlier observations: %d' % len(outliers_removed))"]},{"cell_type":"markdown","metadata":{"id":"iKbBHWIdTtXl"},"source":["##Remove outliers using Interquartile Range method"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"IeFKqZG-T7Cn"},"outputs":[],"source":["# identify outliers with interquartile range\n","from numpy.random import seed\n","from numpy.random import randn\n","from numpy import percentile\n","# seed the random number generator\n","seed(1)\n","# generate univariate observations\n","data = 5 * randn(10000) + 50"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":284,"status":"ok","timestamp":1654551257292,"user":{"displayName":"Chuming Chen","userId":"17839229876463490728"},"user_tz":240},"id":"LsHxjzHhT-QS","outputId":"1f5fcdae-981e-4eb0-c58f-446a1c99a269"},"outputs":[{"output_type":"stream","name":"stdout","text":["Percentiles: 25th=46.685, 75th=53.359, IQR=6.674\n"]}],"source":["# calculate interquartile range\n","q25, q75 = percentile(data, 25), percentile(data, 75)\n","iqr = q75 - q25\n","print('Percentiles: 25th=%.3f, 75th=%.3f, IQR=%.3f' % (q25, q75, iqr))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"P26z_D9kUAyI"},"outputs":[],"source":["# calculate the outlier cutoff\n","cut_off = iqr * 1.5\n","lower, upper = q25 - cut_off, q75 + cut_off"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":277,"status":"ok","timestamp":1654551273851,"user":{"displayName":"Chuming Chen","userId":"17839229876463490728"},"user_tz":240},"id":"7ygpNxrRUDDB","outputId":"8057bd6e-4887-414b-da2d-b05f2372e6a8"},"outputs":[{"output_type":"stream","name":"stdout","text":["Identified outliers: 81\n"]}],"source":["# identify outliers\n","outliers = [x for x in data if x < lower or x > upper]\n","print('Identified outliers: %d' % len(outliers))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":272,"status":"ok","timestamp":1654551277633,"user":{"displayName":"Chuming Chen","userId":"17839229876463490728"},"user_tz":240},"id":"Hca_q8jxUHFq","outputId":"c864e178-46d8-46a2-e16f-2d43c627874a"},"outputs":[{"output_type":"stream","name":"stdout","text":["Non-outlier observations: 9919\n"]}],"source":["# remove outliers\n","outliers_removed = [x for x in data if x >= lower and x <= upper]\n","print('Non-outlier observations: %d' % len(outliers_removed))"]},{"cell_type":"markdown","metadata":{"id":"KInzCDfkYPRq"},"source":["##Remove outliers using Automatic Outlier Detection method\n","\n","A simple approach to identifying outliers is to locate those examples that are far from the\n","other examples in the multi-dimensional feature space. This can work well for feature spaces\n","with low dimensionality (few features), although it can become less reliable as the number of\n","features is increased, referred to as the **curse of dimensionality**. The local outlier factor, or\n","LOF for short, is a technique that attempts to harness the idea of nearest neighbors for outlier\n","detection. Each example is assigned a scoring of how isolated or how likely it is to be outliers\n","based on the size of its local neighborhood. Those examples with the largest score are more\n","likely to be outliers."]},{"cell_type":"markdown","metadata":{"id":"WxaSOQTEYpYA"},"source":["##Diabetes Dataset\n","The dataset classifies patient as\n","either an onset of diabetes within five years or not. \n","```\n","Number of Instances: 768\n","Number of Attributes: 8 plus class \n","For Each Attribute: (all numeric-valued)\n","   1. Number of times pregnant\n","   2. Plasma glucose concentration a 2 hours in an oral glucose tolerance test\n","   3. Diastolic blood pressure (mm Hg)\n","   4. Triceps skin fold thickness (mm)\n","   5. 2-Hour serum insulin (mu U/ml)\n","   6. Body mass index (weight in kg/(height in m)^2)\n","   7. Diabetes pedigree function\n","   8. Age (years)\n","   9. Class variable (0 or 1)\n","Missing Attribute Values: Yes\n","Class Distribution: (class value 1 is interpreted as \"tested positive for\n","   diabetes\")\n","   Class Value  Number of instances\n","   0            500\n","   1            268\n","```\n","\n","You can learn more about the dataset here:\n","\n","* Diabetes Dataset File ([pima-indians-diabetes.csv](https://raw.githubusercontent.com/jbrownlee/Datasets/master/pima-indians-diabetes.csv))\n","* Diabetes Dataset Details ([pima-indians-diabetes.names](https://raw.githubusercontent.com/jbrownlee/Datasets/master/pima-indians-diabetes.names))"]},{"cell_type":"markdown","metadata":{"id":"fSk8mA5LY9LG"},"source":["###Download Diabetes data files"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":11482,"status":"ok","timestamp":1655160423535,"user":{"displayName":"Chuming Chen","userId":"17839229876463490728"},"user_tz":240},"id":"IpRFKdgtZAxn","outputId":"da831354-b3b0-49db-c3f8-5719de602882"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting wget\n","  Downloading wget-3.2.zip (10 kB)\n","Building wheels for collected packages: wget\n","  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for wget: filename=wget-3.2-py3-none-any.whl size=9675 sha256=39926750b7eb133c171cfdc95014980ce6bc6ad20b886d2347b5c8c6ab7d84af\n","  Stored in directory: /root/.cache/pip/wheels/a1/b6/7c/0e63e34eb06634181c63adacca38b79ff8f35c37e3c13e3c02\n","Successfully built wget\n","Installing collected packages: wget\n","Successfully installed wget-3.2\n","\n","Saved under pima-indians-diabetes.csv\n","\n","Saved under pima-indians-diabetes.names\n","6,148,72,35,0,33.6,0.627,50,1\n","1,85,66,29,0,26.6,0.351,31,0\n","8,183,64,0,0,23.3,0.672,32,1\n","1,89,66,23,94,28.1,0.167,21,0\n","0,137,40,35,168,43.1,2.288,33,1\n","5,116,74,0,0,25.6,0.201,30,0\n","3,78,50,32,88,31.0,0.248,26,1\n","10,115,0,0,0,35.3,0.134,29,0\n","2,197,70,45,543,30.5,0.158,53,1\n","8,125,96,0,0,0.0,0.232,54,1\n"]}],"source":["!pip install wget\n","!python -m wget \"https://raw.githubusercontent.com/jbrownlee/Datasets/master/pima-indians-diabetes.csv\" -o pima-indians-diabetes.csv\n","!python -m wget \"https://raw.githubusercontent.com/jbrownlee/Datasets/master/pima-indians-diabetes.names\" -o pima-indians-diabetes.names\n","!head pima-indians-diabetes.csv"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1268,"status":"ok","timestamp":1654551420333,"user":{"displayName":"Chuming Chen","userId":"17839229876463490728"},"user_tz":240},"id":"CxKqHxWoZ7ji","outputId":"11f5e91b-3f95-43a5-f67f-abecb6bb44db"},"outputs":[{"output_type":"stream","name":"stdout","text":["(768, 8) (768,)\n","(537, 8) (231, 8) (537,) (231,)\n"]}],"source":["# load and summarize the dataset\n","from pandas import read_csv\n","from sklearn.model_selection import train_test_split\n","# load the dataset\n","df = read_csv('pima-indians-diabetes.csv', header=None)\n","# retrieve the array\n","data = df.values\n","# split into input and output elements\n","X, y = data[:, :-1], data[:, -1]\n","# summarize the shape of the dataset\n","print(X.shape, y.shape)\n","# split into train (70%) and test sets (30%)\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1)\n","# summarize the shape of the train and test sets\n","print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":309,"status":"ok","timestamp":1654551442945,"user":{"displayName":"Chuming Chen","userId":"17839229876463490728"},"user_tz":240},"id":"WqUE_CgradMj","outputId":"9afe8c7a-6520-498a-c708-79ab1d719a4e"},"outputs":[{"output_type":"stream","name":"stdout","text":["MAE: 0.324\n"]}],"source":["# evaluate model on the raw dataset\n","from pandas import read_csv\n","from sklearn.model_selection import train_test_split\n","from sklearn.linear_model import LinearRegression\n","from sklearn.metrics import mean_absolute_error\n","# load the dataset\n","df = read_csv('pima-indians-diabetes.csv', header=None)\n","# retrieve the array\n","data = df.values\n","# split into input and output elements\n","X, y = data[:, :-1], data[:, -1]\n","# split into train and test sets\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1)\n","# fit the model\n","model = LinearRegression()\n","model.fit(X_train, y_train)\n","# evaluate the model\n","yhat = model.predict(X_test)\n","# evaluate predictions using mean absolute error\n","mae = mean_absolute_error(y_test, yhat)\n","print('MAE: %.3f' % mae)"]},{"cell_type":"markdown","metadata":{"id":"dlqg7DbKar1a"},"source":["Next, we can try removing outliers from the training dataset. The expectation is that the\n","outliers are causing the linear regression model to learn a bias or skewed understanding of the\n","problem, and that removing these outliers from the training set will allow a more effective model\n","to be learned.\n","\n","We can achieve this by defining the **LocalOutlierFactor** model and using it to\n","make a prediction on the training dataset, marking each row in the training dataset as normal\n","(1) or an outlier (-1). We will use the default hyperparameters for the outlier detection model,\n","although it is a good idea to tune the configuration to the specifics of your dataset."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":314,"status":"ok","timestamp":1654551525999,"user":{"displayName":"Chuming Chen","userId":"17839229876463490728"},"user_tz":240},"id":"xQfe83Tnasqz","outputId":"5d827613-96e3-4097-b820-2a4aa79e0073"},"outputs":[{"output_type":"stream","name":"stdout","text":["(537, 8) (537,)\n","(519, 8) (519,)\n","MAE: 0.317\n"]}],"source":["# evaluate model on training dataset with outliers removed\n","from pandas import read_csv\n","from sklearn.model_selection import train_test_split\n","from sklearn.linear_model import LinearRegression\n","from sklearn.neighbors import LocalOutlierFactor\n","from sklearn.metrics import mean_absolute_error\n","# load the dataset\n","df = read_csv('pima-indians-diabetes.csv', header=None)\n","# retrieve the array\n","data = df.values\n","# split into input and output elements\n","X, y = data[:, :-1], data[:, -1]\n","# split into train and test sets\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1)\n","# summarize the shape of the training dataset\n","print(X_train.shape, y_train.shape)\n","# identify outliers in the training dataset\n","lof = LocalOutlierFactor()\n","yhat = lof.fit_predict(X_train)\n","# select all rows that are not outliers\n","mask = yhat != -1\n","X_train, y_train = X_train[mask, :], y_train[mask]\n","# summarize the shape of the updated training dataset\n","print(X_train.shape, y_train.shape)\n","# fit the model without outliers\n","model = LinearRegression()\n","model.fit(X_train, y_train)\n","# evaluate the model\n","yhat = model.predict(X_test)\n","# evaluate predictions\n","mae = mean_absolute_error(y_test, yhat)\n","print('MAE: %.3f' % mae)"]},{"cell_type":"markdown","source":["We can see MAE (Mean Absolute Error) reduced from to 0.324 to 0.317."],"metadata":{"id":"_qm9qvTDMbCY"}}],"metadata":{"colab":{"collapsed_sections":[],"name":"Day_2_Live_Demo_3_Outlier_Identification_and_Removal.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}