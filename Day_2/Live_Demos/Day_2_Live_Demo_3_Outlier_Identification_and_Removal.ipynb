{"cells":[{"cell_type":"markdown","metadata":{"id":"_XaIh9kpwKe-"},"source":["#**Outlier Identification and Removal**"]},{"cell_type":"markdown","metadata":{"id":"X6QcSd0aTFwl"},"source":["In this tutorial, you will learn:\n","\n","* That an outlier is an unlikely observation in a dataset and may have one of many causes.\n","* How to use simple univariate statistics like standard deviation and interquartile range to\n","identify and remove outliers from a data sample.\n","* How to use an outlier detection model to identify and remove rows from a training dataset\n","in order to lift predictive modeling performance.\n","\n","Adapted from Jason Brownlee. 2020. [Data Preparation for Machine Learning](https://machinelearningmastery.com/data-preparation-for-machine-learning/)."]},{"cell_type":"markdown","metadata":{"id":"8GhsEsk5Qbrh"},"source":["#Outlier Identification and Removal\n","##What are Outliers?\n","\n","An outlier is an observation that is unlike the other observations. They are rare, distinct, or do\n","notâ€€fit in some way.\n","\n","We will generally define outliers as samples that are exceptionally far from the\n","mainstream of the data.\n","\n","Outliers can have many causes, such as:\n","\n","* Measurement or input error.\n","\n","* Data corruption.\n","\n","* True outlier observation.\n","\n","There is no precise way to define and identify outliers in general because of the specifics of\n","each dataset. Instead, you, or a domain expert, must interpret the raw observations and decide\n","whether a value is an outlier or not."]},{"cell_type":"markdown","metadata":{"id":"UfT4GpLuQ_qd"},"source":["##Remove outliers using Standard Deviation method"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6,"status":"ok","timestamp":1655171500194,"user":{"displayName":"Chuming Chen","userId":"17839229876463490728"},"user_tz":240},"id":"HKh3tdwURBl9","outputId":"8f14472e-83ca-4502-d3ce-f9d6a497d3b0"},"outputs":[{"output_type":"stream","name":"stdout","text":["mean=50.049 stdv=4.994\n"]}],"source":["# identifiy outliers using Standard Deviation method\n","from numpy.random import seed\n","from numpy.random import randn\n","from numpy import mean\n","from numpy import std\n","# seed the random number generator\n","seed(1)\n","# generate univariate observations\n","data = 5 * randn(10000) + 50\n","# summarize\n","print('mean=%.3f stdv=%.3f' % (mean(data), std(data)))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yirudZwiRagS"},"outputs":[],"source":["# calculate summary statistics\n","data_mean, data_std = mean(data), std(data)\n","# define outliers\n","cut_off = data_std * 3\n","lower, upper = data_mean - cut_off, data_mean + cut_off"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4,"status":"ok","timestamp":1655171568054,"user":{"displayName":"Chuming Chen","userId":"17839229876463490728"},"user_tz":240},"id":"e6m6_COPRevk","outputId":"3307d057-c2ac-4f4e-c2ee-4815368e3e8f"},"outputs":[{"output_type":"stream","name":"stdout","text":["Identified outliers: 29\n"]}],"source":["# identify outliers\n","outliers = [x for x in data if x < lower or x > upper]\n","print('Identified outliers: %d' % len(outliers))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":128,"status":"ok","timestamp":1655171654042,"user":{"displayName":"Chuming Chen","userId":"17839229876463490728"},"user_tz":240},"id":"emxpuI6XRxtl","outputId":"e8ad5489-1108-407a-bed6-47f8629347a7"},"outputs":[{"output_type":"stream","name":"stdout","text":["Non-outlier observations: 9971\n"]}],"source":["# identify non outliers\n","non_outliers = [x for x in data if x >= lower and x <= upper]\n","print('Non-outlier observations: %d' % len(non_outliers))"]},{"cell_type":"markdown","metadata":{"id":"iKbBHWIdTtXl"},"source":["##Remove outliers using Interquartile Range method"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"IeFKqZG-T7Cn"},"outputs":[],"source":["# identify outliers with interquartile range\n","from numpy.random import seed\n","from numpy.random import randn\n","from numpy import percentile\n","# seed the random number generator\n","seed(1)\n","# generate univariate observations\n","data = 5 * randn(10000) + 50"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":139,"status":"ok","timestamp":1655171694600,"user":{"displayName":"Chuming Chen","userId":"17839229876463490728"},"user_tz":240},"id":"LsHxjzHhT-QS","outputId":"f8c9db40-0d02-43bc-b5f1-cdc2e6fdf9b5"},"outputs":[{"output_type":"stream","name":"stdout","text":["Percentiles: 25th=46.685, 75th=53.359, IQR=6.674\n"]}],"source":["# calculate interquartile range\n","q25, q75 = percentile(data, 25), percentile(data, 75)\n","iqr = q75 - q25\n","print('Percentiles: 25th=%.3f, 75th=%.3f, IQR=%.3f' % (q25, q75, iqr))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"P26z_D9kUAyI"},"outputs":[],"source":["# calculate the outlier cutoff\n","cut_off = iqr * 1.5\n","lower, upper = q25 - cut_off, q75 + cut_off"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":207,"status":"ok","timestamp":1655171734683,"user":{"displayName":"Chuming Chen","userId":"17839229876463490728"},"user_tz":240},"id":"7ygpNxrRUDDB","outputId":"ce58643d-5098-465d-d391-c24cd4f23904"},"outputs":[{"output_type":"stream","name":"stdout","text":["Identified outliers: 81\n"]}],"source":["# identify outliers\n","outliers = [x for x in data if x < lower or x > upper]\n","print('Identified outliers: %d' % len(outliers))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":163,"status":"ok","timestamp":1655171763546,"user":{"displayName":"Chuming Chen","userId":"17839229876463490728"},"user_tz":240},"id":"Hca_q8jxUHFq","outputId":"c89ae373-9fea-469e-d66c-eb869c505084"},"outputs":[{"output_type":"stream","name":"stdout","text":["Non-outlier observations: 9919\n"]}],"source":["# identify non outliers\n","non_outliers = [x for x in data if x >= lower and x <= upper]\n","print('Non-outlier observations: %d' % len(non_outliers))"]},{"cell_type":"markdown","metadata":{"id":"KInzCDfkYPRq"},"source":["##Remove outliers using Automatic Outlier Detection method\n","\n","A simple approach to identifying outliers is to locate those examples that are far from the\n","other examples in the multi-dimensional feature space. This can work well for feature spaces\n","with low dimensionality (few features), although it can become less reliable as the number of\n","features is increased, referred to as the **curse of dimensionality**. The local outlier factor, or\n","LOF for short, is a technique that attempts to harness the idea of nearest neighbors for outlier\n","detection. Each example is assigned a scoring of how isolated or how likely it is to be outliers\n","based on the size of its local neighborhood. Those examples with the largest score are more\n","likely to be outliers."]},{"cell_type":"markdown","metadata":{"id":"WxaSOQTEYpYA"},"source":["##Diabetes Dataset\n","The dataset classifies patient as\n","either an onset of diabetes within five years or not. \n","```\n","Number of Instances: 768\n","Number of Attributes: 8 plus class \n","For Each Attribute: (all numeric-valued)\n","   1. Number of times pregnant\n","   2. Plasma glucose concentration a 2 hours in an oral glucose tolerance test\n","   3. Diastolic blood pressure (mm Hg)\n","   4. Triceps skin fold thickness (mm)\n","   5. 2-Hour serum insulin (mu U/ml)\n","   6. Body mass index (weight in kg/(height in m)^2)\n","   7. Diabetes pedigree function\n","   8. Age (years)\n","   9. Class variable (0 or 1)\n","Missing Attribute Values: Yes\n","Class Distribution: (class value 1 is interpreted as \"tested positive for\n","   diabetes\")\n","   Class Value  Number of instances\n","   0            500\n","   1            268\n","```\n","\n","You can learn more about the dataset here:\n","\n","* Diabetes Dataset File ([pima-indians-diabetes.csv](https://raw.githubusercontent.com/jbrownlee/Datasets/master/pima-indians-diabetes.csv))\n","* Diabetes Dataset Details ([pima-indians-diabetes.names](https://raw.githubusercontent.com/jbrownlee/Datasets/master/pima-indians-diabetes.names))"]},{"cell_type":"markdown","metadata":{"id":"fSk8mA5LY9LG"},"source":["###Download Diabetes data files"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":10611,"status":"ok","timestamp":1655216579862,"user":{"displayName":"Chuming Chen","userId":"17839229876463490728"},"user_tz":240},"id":"IpRFKdgtZAxn","outputId":"21f85cc6-79c5-4aab-eadc-2a27dcdefb3a"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting wget\n","  Downloading wget-3.2.zip (10 kB)\n","Building wheels for collected packages: wget\n","  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for wget: filename=wget-3.2-py3-none-any.whl size=9675 sha256=6c4d8d43929ab12b371b150b040b7eb0a4ecc8fbd8549115b52dfcec88b4ed56\n","  Stored in directory: /root/.cache/pip/wheels/a1/b6/7c/0e63e34eb06634181c63adacca38b79ff8f35c37e3c13e3c02\n","Successfully built wget\n","Installing collected packages: wget\n","Successfully installed wget-3.2\n","\n","Saved under pima-indians-diabetes.csv\n","\n","Saved under pima-indians-diabetes.names\n"]}],"source":["!pip install wget\n","!python -m wget \"https://raw.githubusercontent.com/jbrownlee/Datasets/master/pima-indians-diabetes.csv\" -o pima-indians-diabetes.csv\n","!python -m wget \"https://raw.githubusercontent.com/jbrownlee/Datasets/master/pima-indians-diabetes.names\" -o pima-indians-diabetes.names"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":954,"status":"ok","timestamp":1655171906529,"user":{"displayName":"Chuming Chen","userId":"17839229876463490728"},"user_tz":240},"id":"CxKqHxWoZ7ji","outputId":"f6e3c531-5e34-4121-fe72-ad318bdb01ee"},"outputs":[{"output_type":"stream","name":"stdout","text":["(768, 8) (768,)\n","(537, 8) (231, 8) (537,) (231,)\n"]}],"source":["# load and summarize the dataset\n","from pandas import read_csv\n","from sklearn.model_selection import train_test_split\n","# load the dataset\n","df = read_csv('pima-indians-diabetes.csv', header=None)\n","# retrieve the array\n","data = df.values\n","# split into input and output elements\n","X, y = data[:, :-1], data[:, -1]\n","# summarize the shape of the dataset\n","print(X.shape, y.shape)\n","# split into train (70%) and test sets (30%)\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1)\n","# summarize the shape of the train and test sets\n","print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":328,"status":"ok","timestamp":1655171943356,"user":{"displayName":"Chuming Chen","userId":"17839229876463490728"},"user_tz":240},"id":"WqUE_CgradMj","outputId":"72aaaa1d-21fb-478b-a511-c0d19cc356b2"},"outputs":[{"output_type":"stream","name":"stdout","text":["MAE: 0.324\n"]}],"source":["# evaluate model on the raw dataset\n","from pandas import read_csv\n","from sklearn.model_selection import train_test_split\n","from sklearn.linear_model import LinearRegression\n","from sklearn.metrics import mean_absolute_error\n","# load the dataset\n","df = read_csv('pima-indians-diabetes.csv', header=None)\n","# retrieve the array\n","data = df.values\n","# split into input and output elements\n","X, y = data[:, :-1], data[:, -1]\n","# split into train and test sets\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1)\n","# fit the model\n","model = LinearRegression()\n","model.fit(X_train, y_train)\n","# evaluate the model\n","yhat = model.predict(X_test)\n","# evaluate predictions using mean absolute error\n","mae = mean_absolute_error(y_test, yhat)\n","print('MAE: %.3f' % mae)"]},{"cell_type":"markdown","metadata":{"id":"dlqg7DbKar1a"},"source":["Next, we can try removing outliers from the training dataset. The expectation is that the\n","outliers are causing the linear regression model to learn a bias or skewed understanding of the\n","problem, and that removing these outliers from the training set will allow a more effective model\n","to be learned.\n","\n","We can achieve this by defining the **LocalOutlierFactor** model and using it to\n","make a prediction on the training dataset, marking each row in the training dataset as normal\n","(1) or an outlier (-1). We will use the default hyperparameters for the outlier detection model,\n","although it is a good idea to tune the configuration to the specifics of your dataset."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":330,"status":"ok","timestamp":1655172105555,"user":{"displayName":"Chuming Chen","userId":"17839229876463490728"},"user_tz":240},"id":"xQfe83Tnasqz","outputId":"1af16652-9b71-4f27-8c86-0a44e2d2682b"},"outputs":[{"output_type":"stream","name":"stdout","text":["(537, 8) (537,)\n","(519, 8) (519,)\n","MAE: 0.317\n"]}],"source":["# evaluate model on training dataset with outliers removed\n","from pandas import read_csv\n","from sklearn.model_selection import train_test_split\n","from sklearn.linear_model import LinearRegression\n","from sklearn.neighbors import LocalOutlierFactor\n","from sklearn.metrics import mean_absolute_error\n","# load the dataset\n","df = read_csv('pima-indians-diabetes.csv', header=None)\n","# retrieve the array\n","data = df.values\n","# split into input and output elements\n","X, y = data[:, :-1], data[:, -1]\n","# split into train and test sets\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1)\n","# summarize the shape of the training dataset\n","print(X_train.shape, y_train.shape)\n","# identify outliers in the training dataset\n","lof = LocalOutlierFactor()\n","# Fit the model to the training set X and return the labels.\n","yhat = lof.fit_predict(X_train)\n","# select all rows that are not outliers\n","mask = yhat != -1\n","X_train, y_train = X_train[mask, :], y_train[mask]\n","# summarize the shape of the updated training dataset\n","print(X_train.shape, y_train.shape)\n","# fit the model without outliers\n","model = LinearRegression()\n","model.fit(X_train, y_train)\n","# evaluate the model\n","yhat = model.predict(X_test)\n","# evaluate predictions\n","mae = mean_absolute_error(y_test, yhat)\n","print('MAE: %.3f' % mae)"]},{"cell_type":"markdown","source":["We can see MAE (Mean Absolute Error) reduced from to 0.324 to 0.317."],"metadata":{"id":"_qm9qvTDMbCY"}}],"metadata":{"colab":{"collapsed_sections":[],"name":"Day_2_Live_Demo_3_Outlier_Identification_and_Removal.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}